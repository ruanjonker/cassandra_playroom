###
### Metric Collector for Apache Cassandra Configuration
###

### The frequency that metrics are reported to the Metrics Collector.
### Default - 30s
metric_sampling_interval_in_seconds: 30

#####################################################################
### List of metrics to allow or deny
###
### pattern: regex pattern to search, can be a sub-match or full match
### scope: 'global' will affect all data. 'datalog' will only affect the datalog
### policy: 'allow' or 'deny'
### The last applicable rule wins, which works similarly to iptables firewall rules:
###   - A metric that would be denied by a rule and then allowed by another would be allowed.
###   - A metric that would be allowed by a rule and then denied by another would be denied.
### This allows to apply efficient filters on table level metrics for example and allow just a 
### subset of those to match the dashboards requirements.
### Filter rules are applied both on the name of the Cassandra metric and a cleaned/formatted
### version of the metric name:
###   - org.apache.cassandra.metrics.Table.LiveSSTableCount
###   - org.apache.cassandra.metrics.table.live_ss_table_count
### In the event the metric name and the cleaned metric name result in a differing policy,
### the deny policy would be applied.
### Default - allow all

# Below sample rules allow to extract only a subset of table level metrics and lighten the load
# for clusters with 100s of tables.
filtering_rules:
  #Deny everything
  - policy: deny
    pattern: .*
    scope: global
  #Allow cassandra and jvm metrics
  - policy: allow
    pattern: org\.apache\.cassandra\.metrics\.
    scope: global  
  - policy: allow
    pattern: jvm\.
    scope: global
  #Deny rules by category
  #Ignore system tables
  - policy: deny
    pattern: org\.apache\.cassandra\.metrics\.table\.(\w+)\.(system|system_auth|system_distributed|system_traces)
    scope: global  
  #Igenore system keyspaces
  - policy: deny
    pattern: org\.apache\.cassandra\.metrics\.keyspace\.(\w+)\.(system|system_auth|system_distributed|system_traces)
    scope: global


#######################################################################
### Disk Logging of Metrics and Events (DataLog)
###
### The default mode enables metrics collection and diagnostic events
### to be stored on local on disk in the location defined by data_dir.
###
### This data can be used to help diagnose cluster / node level problems
### by DataStax support: https://www.datastax.com/keepcalm
###
### The raw data can be parsed using the included datalog-parser.py script
write_to_disk_enabled: true

### The maximum number amount of on disk data to store in MB
### Default - 5000
#data_dir_max_size_in_mb: 5000

### Directory to store collected metrics.
### Default directory is Cassandra data directory. You can customize the location by uncomment and correct data_dir
#data_dir: /var/lib/cassandra

### Directory to store logs for collected metrics. The log file is cassandra-collectd.log
### Default directory is Cassandra log directory. You can customize the location by uncomment and correct log_dir
#log_dir: /var/log/cassandra
